# MIT 6.S191 - Intro to deep learning

This is a really high quality course from MIT which covers the basics of deep learning without delving too much into the math. It's really good to get a first overall view of the field, understanding the basic concepts and the most used structures.

The first 6 lessons are the most useful ones: the other ones are more focused on specific topics which might not be as helpful for a general introduction.

The labs are somewhat helpful, but are quite difficult as a first hands-on approach. They use Colab, but do not introduce it.

- [MIT 6.S191 - Intro to deep learning](#mit-6s191---intro-to-deep-learning)
  - [Tools](#tools)
  - [Material](#material)
  - [Topics](#topics)

## Tools

**Language**: Python  
**Deep learning**: Tensorflow and Keras (some quick mentions)  
**Other tools**: Google Colab (not explained)

## Material

**Website**

http://introtodeeplearning.com/  
A summary of all the course contents. Links to lectures, material and labs.

**YouTube playlist of past lectures**

https://www.youtube.com/playlist?list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI  
A playlist, updated year by year, containing all the lectures of the past editions of the course. It's recommended to follow the most recent one.

## Topics

**Intro**  
Perceptrons, activation functions, loss, feedforward networks (FFN), backpropagation, batching, Stochastic Gradient Descent (SGD)

**Recurrence**  
recurrence, recurrent neural networks (RNN), Backpropagation Through Time (BPTT), variable length sequences, vanishing and exploding gradient, LSTM, attention

**Convoloution**  
computer vision, filters, convolution, Convolutional Neural Networks (CNN), pooling, object detection, RCNN, fully convolutional NN

**Deep generative modeling**  
supervised and unsupervised learning, generative modeling, latent variables, autoencoders, Variable Auto Encoders (VAE), regularization, stochastic sampling reparametrization, Generative Adversarial Networks (GAN)

**Reinforcement learning**  
reinforcement learning, Q-learning, policy gradient, training, troubles with simulations